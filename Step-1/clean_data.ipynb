{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481e768e",
   "metadata": {},
   "source": [
    "Step 1 - cleaning data from CSV file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef1b48",
   "metadata": {},
   "source": [
    "1.1 - deducting duplicte emails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed5ed77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate email entries dropped: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "file_path = 'Data.csv'\n",
    "# reading th csv file using pandas\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Identify masked emails (those that contain \"*****\")\n",
    "masked = df['email'].str.contains(r'\\*{5}', na=False)\n",
    "unmasked_emails = df[~masked]\n",
    "\n",
    "# Count duplicates\n",
    "total_unmasked = len(unmasked_emails)\n",
    "unique_unmasked = unmasked_emails[\"email\"].nunique()\n",
    "duplicates_dropped = total_unmasked - unique_unmasked\n",
    "\n",
    "print(f\"Duplicate email entries dropped: {duplicates_dropped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a64a5",
   "metadata": {},
   "source": [
    "So,  no duplicate emails obtain as i took \" ***** \" as unique email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61938cb",
   "metadata": {},
   "source": [
    "1.2 - Replaceing has_joined_events from YES/NO to True/ False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d285847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in 'has_joined_event' column: 648\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "5     False\n",
      "6      True\n",
      "7      True\n",
      "8      True\n",
      "9      True\n",
      "10     True\n",
      "Name: has_joined_event, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df[\"has_joined_event\"] = df[\"has_joined_event\"].str.strip().str.lower().map({\n",
    "    \"yes\": True,\n",
    "    \"no\": False\n",
    "})\n",
    "\n",
    "\n",
    "# Print the only has joined event column with total number of rows\n",
    "print(f\"Total rows in 'has_joined_event' column: {len(df['has_joined_event'])}\")\n",
    "print(df[\"has_joined_event\"].head(11))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361deff4",
   "metadata": {},
   "source": [
    "So, data gas been manpluted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a1dd8",
   "metadata": {},
   "source": [
    "1.3 dentify and flag rows where:\n",
    " - LinkedIn profile is missing or incomplete \n",
    " - The job title is blank "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff0b98",
   "metadata": {},
   "source": [
    "flaging linkdin profiles in 3 types\n",
    "- valid \n",
    "- missing \n",
    "- incorrect \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd7c9037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                        name  \\\n",
       " 0                Venkatesh R   \n",
       " 1                 Mark Jawut   \n",
       " 2              Avinash Kumar   \n",
       " 3                Wilson Juma   \n",
       " 4                     Suneel   \n",
       " 5  Aishwarya kumar choudhary   \n",
       " 6            AAKASH JANGEETI   \n",
       " 7               Arushi Yadav   \n",
       " 8           Aashish Ailawadi   \n",
       " 9             Aashish Sharma   \n",
       " \n",
       "                       What is your LinkedIn profile? LinkedIn Status  \n",
       " 0      https://linkedin.com/in/venkatesh-r-42845a282           Valid  \n",
       " 1                                          MarkJawut      Incomplete  \n",
       " 2                  linkedin.com/in/Avinash.kumar5167           Valid  \n",
       " 3                      linkedin.com/in/wilsonjuma254           Valid  \n",
       " 4                                                NaN         Missing  \n",
       " 5  www.linkedin.com/in/ aishwarya-kumar-choudhary...           Valid  \n",
       " 6     https://linkedin.com/in/aakash-royal-a8015821b           Valid  \n",
       " 7  https://www.linkedin.com/in/arushi-yadav-68744...           Valid  \n",
       " 8             https://www.linkedin.com/in/aashishail           Valid  \n",
       " 9  https://www.linkedin.com/in/aashish-sharma-0a7...           Valid  ,\n",
       " LinkedIn Status\n",
       " Valid         464\n",
       " Incomplete    174\n",
       " Missing        10\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and analyze the LinkedIn column\n",
    "linkedin_col = 'What is your LinkedIn profile?'\n",
    "\n",
    "def check_linkedin_status(link):\n",
    "    if pd.isna(link) or str(link).strip() == '':\n",
    "        return 'Missing'\n",
    "    link = str(link).strip().lower()\n",
    "    if 'linkedin.com/in/' in link:\n",
    "        return 'Valid'\n",
    "    return 'Incomplete'\n",
    "\n",
    "# Apply the function to classify each LinkedIn entry\n",
    "df['LinkedIn Status'] = df[linkedin_col].apply(check_linkedin_status)\n",
    "\n",
    "# Display the counts for each status and show a preview of the flagged data\n",
    "status_counts = df['LinkedIn Status'].value_counts()\n",
    "df[['name', linkedin_col, 'LinkedIn Status']].head(10), status_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fff5b",
   "metadata": {},
   "source": [
    "doing similar for job title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c86e609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of missing job titles:\n",
      "             name            email Job Title\n",
      "317  Maxwel Maina  *****@gmail.com       NaN\n",
      "445        Raihan  *****@gmail.com       NaN\n"
     ]
    }
   ],
   "source": [
    "# Check if the 'Job Title' column is empty or missing\n",
    "df['Job Title Status'] = df['Job Title'].apply(\n",
    "    lambda x: 'Missing' if pd.isna(x) or str(x).strip() == '' else 'Present'\n",
    ")\n",
    "\n",
    "# Count how many are missing vs present\n",
    "job_title_status_counts = df['Job Title Status'].value_counts()\n",
    "\n",
    "# Show a sample of the updated data\n",
    "df[['name', 'Job Title', 'Job Title Status']].head(10), job_title_status_counts \n",
    "\n",
    "\n",
    "#show details of missing job titles\n",
    "missing_job_titles = df[df['Job Title Status'] == 'Missing'][['name', 'email', 'Job Title']]    \n",
    "print(\"Details of missing job titles:\")\n",
    "print(missing_job_titles.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e69ef",
   "metadata": {},
   "source": [
    "Completing Step 1 by saving all the  saving all new data in a new csv file called cleaned_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "549d0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new xl file\n",
    "output_file_path = 'Cleaned_Data.xlsx'  \n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Saving to a CSV file\n",
    "output_csv_path = 'cleaned_output.csv '\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
